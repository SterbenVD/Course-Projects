@article{NCalgo,
  title = {Opportunities for neuromorphic computing algorithms and applications},
  author = {Schuman, Catherine D. and Kulkarni, Shruti R. and Parsa, Maryam and Mitchell, J. Parker and Date, Prasanna and Kay, Bill},
  journal = {Nature Computational Science},
  volume = {2},
  number = {1},
  pages = {10--19},
  year = {2022},
  doi = {10.1038/s43588-021-00184-y},
  url = {https://doi.org/10.1038/s43588-021-00184-y},
}
@article{MemristorProgress,
  author={Yang, Xiaoxuan and Taylor, Brady and Wu, Ailong and Chen, Yiran and Chua, Leon O.},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers}, 
  title={Research Progress on Memristor: From Synapses to Computing Systems}, 
  year={2022},
  volume={69},
  number={5},
  pages={1845-1857},
  keywords={Memristors;Synapses;Reliability;Programming;Computer architecture;Transistors;Virtual machine monitors;Memristor;memristive devices;processing-in-memory;reliability;in-situ learning;neuromorphic computing},
  doi={10.1109/TCSI.2022.3159153}}

@article{BiCoss,
  author={Yang, Shuangming and Wang, Jiang and Hao, Xinyu and Li, Huiyan and Wei, Xile and Deng, Bin and Loparo, Kenneth A.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={BiCoSS: Toward Large-Scale Cognition Brain With Multigranular Neuromorphic Architecture}, 
  year={2022},
  volume={33},
  number={7},
  pages={2801-2815},
  keywords={Computer architecture;Computational modeling;Biological system modeling;Routing;Neurons;Cognition;Brain modeling;Brain-inspired computing;computational neuroscience;field-programmable gate array (FPGA);large-scale spiking neural network (SNN);neuromorphic},
  doi={10.1109/TNNLS.2020.3045492}}

@article{CerebelluMorphic,
  author={Yang, Shuangming and Wang, Jiang and Zhang, Nan and Deng, Bin and Pang, Yanwei and Azghadi, Mostafa Rahimi},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={CerebelluMorphic: Large-Scale Neuromorphic Model and Architecture for Supervised Motor Learning}, 
  year={2022},
  volume={33},
  number={9},
  pages={4398-4412},
  keywords={Brain modeling;Cerebellum;Neurons;Biological system modeling;Computational modeling;Neuromorphics;Computer architecture;Cerebellum model;motor learning;neuromorphic engineering;spiking neural network (SNN);supervised learning},
  doi={10.1109/TNNLS.2021.3057070}}

@misc{SNNreview,
      title={Implementing Spiking Neural Networks on Neuromorphic Architectures: A Review}, 
      author={Phu Khanh Huynh and M. Lakshmi Varshika and Ankita Paul and Murat Isik and Adarsha Balaji and Anup Das},
      year={2022},
      eprint={2202.08897},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@article{FaultTolerant,
  author={Yang, Shuangming and Wang, Jiang and Deng, Bin and Azghadi, Mostafa Rahimi and Linares-Barranco, Bernabe},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Neuromorphic Context-Dependent Learning Framework With Fault-Tolerant Spike Routing}, 
  year={2022},
  volume={33},
  number={12},
  pages={7126-7140},
  keywords={Neuromorphics;Neurons;Fault tolerant systems;Brain modeling;Task analysis;Context modeling;Brain modeling;Neural networks;Brain inspired;context-dependent learning;fault tolerant;neuromorphic computing;spiking neural network (SNN)},
  doi={10.1109/TNNLS.2021.3084250}}


@article{Spiking,
author = {Rathi, Nitin and Chakraborty, Indranil and Kosta, Adarsh and Sengupta, Abhronil and Ankit, Aayush and Panda, Priyadarshini and Roy, Kaushik},
title = {Exploring Neuromorphic Computing Based on Spiking Neural Networks: Algorithms to Hardware},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3571155},
doi = {10.1145/3571155},
abstract = {Neuromorphic Computing, a concept pioneered in the late 1980s, is receiving a lot of attention lately due to its promise of reducing the computational energy, latency, as well as learning complexity in artificial neural networks. Taking inspiration from neuroscience, this interdisciplinary field performs a multi-stack optimization across devices, circuits, and algorithms by providing an end-to-end approach to achieving brain-like efficiency in machine intelligence. On one side, neuromorphic computing introduces a new algorithmic paradigm, known as Spiking Neural Networks (SNNs), which is a significant shift from standard deep learning and transmits information as spikes&nbsp;(“1” or “0”) rather than analog values. This has opened up novel algorithmic research directions to formulate methods to represent data in spike-trains, develop neuron models that can process information over time, design learning algorithms for event-driven dynamical systems, and engineer network architectures amenable to sparse, asynchronous, event-driven computing to achieve lower power consumption. On the other side, a parallel research thrust focuses on development of efficient computing platforms for new algorithms. Standard accelerators that are amenable to deep learning workloads are not particularly suitable to handle processing across multiple timesteps efficiently. To that effect, researchers have designed neuromorphic hardware that rely on event-driven sparse computations as well as efficient matrix operations. While most large-scale neuromorphic systems have been explored based on CMOS technology, recently, Non-Volatile Memory (NVM) technologies show promise toward implementing bio-mimetic functionalities on single devices. In this article, we outline several strides that neuromorphic computing based on spiking neural networks (SNNs) has taken over the recent past, and we present our outlook on the challenges that this field needs to overcome to make the bio-plausibility route a successful one.},
journal = {ACM Comput. Surv.},
month = {mar},
articleno = {243},
numpages = {49},
keywords = {Neuromorphic Computing, Spiking Neural Networks, bio-plausible learning, spike-based backpropagation, event cameras, In-Memory Computing, Non-Volatile Memories, asynchronous communication}
}

@INPROCEEDINGS{extra,
  author={Cai, Zongyuan and Li, Xinze},
  booktitle={2021 IEEE International Conference on Artificial Intelligence and Industrial Design (AIID)}, 
  title={Neuromorphic Brain-Inspired Computing with Hybrid Neural Networks}, 
  year={2021},
  volume={},
  number={},
  pages={343-347},
  keywords={Computers;Neuromorphics;Computational modeling;Biological system modeling;Software algorithms;Ecosystems;Computer architecture;Neuromorphic Brain-Inspired Computing;Hybrid Neural Networks},
  doi={10.1109/AIID51893.2021.9456483}}
